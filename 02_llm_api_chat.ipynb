{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8qiFjeV2NYA"
      },
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFXVgBlm2DNi",
        "outputId": "113bca43-cac6-48c5-b73c-764dafa1ab51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy>=1.20.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.10.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2.19.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (2.7.0)\n",
            "Requirement already satisfied: transformers>=4.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (4.52.3)\n",
            "Requirement already satisfied: requests>=2.27.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (2.32.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (0.32.2)\n",
            "Requirement already satisfied: accelerate>=0.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (1.7.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.96 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (0.2.0)\n",
            "Requirement already satisfied: tokenizers>=0.12.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (0.21.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (3.6.0)\n",
            "Requirement already satisfied: regex>=2022.3.15 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (2024.11.6)\n",
            "Requirement already satisfied: plotly>=5.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (6.1.2)\n",
            "Requirement already satisfied: wandb>=0.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (0.19.11)\n",
            "Requirement already satisfied: pytest>=7.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (8.3.5)\n",
            "Requirement already satisfied: jupytext>=1.13.8 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (1.17.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.3.0->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (76.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.5.1)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.18.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.10.0->-r requirements.txt (line 11)) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers>=4.18.0->-r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from transformers>=4.18.0->-r requirements.txt (line 12)) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.27.0->-r requirements.txt (line 15)) (2025.1.31)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface_hub>=0.5.0->-r requirements.txt (line 16)) (1.1.2)\n",
            "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 17)) (7.0.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.0.0->-r requirements.txt (line 22)) (0.70.16)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /home/codespace/.local/lib/python3.12/site-packages (from plotly>=5.6.0->-r requirements.txt (line 26)) (1.41.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/codespace/.local/lib/python3.12/site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /home/codespace/.local/lib/python3.12/site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (4.3.8)\n",
            "Requirement already satisfied: pydantic<3 in /home/codespace/.local/lib/python3.12/site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (2.11.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /home/codespace/.local/lib/python3.12/site-packages (from wandb>=0.12.0->-r requirements.txt (line 29)) (1.3.6)\n",
            "Requirement already satisfied: iniconfig in /home/codespace/.local/lib/python3.12/site-packages (from pytest>=7.0.0->-r requirements.txt (line 30)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from pytest>=7.0.0->-r requirements.txt (line 30)) (1.6.0)\n",
            "Requirement already satisfied: markdown-it-py>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /home/codespace/.local/lib/python3.12/site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (0.4.2)\n",
            "Requirement already satisfied: nbformat in /home/codespace/.local/lib/python3.12/site-packages (from jupytext>=1.13.8->-r requirements.txt (line 31)) (5.10.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.45.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/codespace/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (3.12.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.12.0->-r requirements.txt (line 29)) (4.0.12)\n",
            "Requirement already satisfied: rich in /home/codespace/.local/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (14.0.0)\n",
            "Requirement already satisfied: namex in /home/codespace/.local/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.1.0)\n",
            "Requirement already satisfied: optree in /home/codespace/.local/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/codespace/.local/lib/python3.12/site-packages (from markdown-it-py>=1.0->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic<3->wandb>=0.12.0->-r requirements.txt (line 29)) (0.4.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.10.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/codespace/.local/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->-r requirements.txt (line 11)) (3.0.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /home/codespace/.local/lib/python3.12/site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /home/codespace/.local/lib/python3.12/site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/codespace/.local/lib/python3.12/site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (5.14.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0.0->-r requirements.txt (line 22)) (1.20.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.12.0->-r requirements.txt (line 29)) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat->jupytext>=1.13.8->-r requirements.txt (line 31)) (0.25.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow>=2.8.0->-r requirements.txt (line 10)) (2.19.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "# Additional packages for LLM API interaction\n",
        "%pip install requests\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "import time\n",
        "import logging\n",
        "import argparse\n",
        "from typing import Optional\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('utils', exist_ok=True)\n",
        "os.makedirs('results/part_2', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLWxqSh32V9j"
      },
      "source": [
        "## 1. Connecting to the Hugging Face API\n",
        "\n",
        "The Hugging Face Inference API provides access to many language models. We'll use models that are available on the free tier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SZBsxtX2Va-",
        "outputId": "12c9902e-c980-45f9-a574-9d7a851aa382"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-06-06 18:39:04.151168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749235144.698934    4272 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749235144.894902    4272 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749235146.152766    4272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749235146.152812    4272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749235146.152816    4272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749235146.152819    4272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-06 18:39:06.235794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a swollen rectum\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load tokenizer and model once\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "def query(payload):\n",
        "    \"\"\"\n",
        "    Send a query to the Hugging Face API\n",
        "\n",
        "    Args:\n",
        "        payload: Dictionary containing the query parameters\n",
        "\n",
        "    Returns:\n",
        "        The API response\n",
        "    \"\"\"\n",
        "    text_to_process = payload.get(\"inputs\", \"\")\n",
        "    tokenized_inputs = tokenizer(text_to_process, return_tensors=\"pt\")\n",
        "    generated_tokens = model.generate(**tokenized_inputs)\n",
        "    decoded_output = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "    return decoded_output\n",
        "\n",
        "# Test the query function\n",
        "test_payload = {\"inputs\": \"What are the symptoms of diabetes?\"}\n",
        "response = query(test_payload)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Oa1ME12dgN"
      },
      "source": [
        "## 2. Creating Simple Chat Scripts\n",
        "\n",
        "Your task is to create two simple scripts that interact with the Hugging Face API:\n",
        "\n",
        "1. A basic one-off chat script (`utils/one_off_chat.py`)\n",
        "2. A contextual conversation script (`utils/conversation.py`)\n",
        "\n",
        "### One-Off Chat Script\n",
        "\n",
        "Create a script that handles independent interactions (each prompt/response is separate):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "-HTOvSMG2dLs",
        "outputId": "6c6ff4a1-a25f-4432-b668-b2ef1bfd6466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Simple LLM Chat! Type 'exit' to quit.\n"
          ]
        }
      ],
      "source": [
        "# utils/one_off_chat.py\n",
        "\n",
        "import requests\n",
        "import argparse\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "def get_response(prompt, model_name=\"google/flan-t5-base\"):\n",
        "    \"\"\"\n",
        "    Get a response from the model\n",
        "\n",
        "    Args:\n",
        "        prompt: The prompt to send to the model\n",
        "        model_name: Name of the model to use\n",
        "        api_key: API key for authentication (optional for some models)\n",
        "\n",
        "    Returns:\n",
        "        The model's response\n",
        "    \"\"\"\n",
        "    # TODO: Implement the get_response function\n",
        "    # Set up the API URL and headers\n",
        "    # Create a payload with the prompt\n",
        "    # Send the payload to the API\n",
        "    # Extract and return the generated text from the response\n",
        "    # Handle any errors that might occur\n",
        "    API_URL = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
        "    payload = {\"inputs\": prompt}\n",
        "    try:\n",
        "        generator = pipeline(\"text2text-generation\", model=model_name)\n",
        "        response = generator(prompt, max_new_tokens=100)[0]['generated_text']\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def run_chat():\n",
        "    \"\"\"Run an interactive chat session\"\"\"\n",
        "    print(\"Welcome to the Simple LLM Chat! Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # TODO: Get response from the model\n",
        "        # Print the response\n",
        "        response = get_response(user_input, model_name=model_name, api_key=api_key)\n",
        "        print(f\"Bot: {response}\")\n",
        "\n",
        "def main():\n",
        "    run_chat()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSYtiWHc2rYL"
      },
      "source": [
        "### Contextual Conversation Script\n",
        "\n",
        "Create a script that maintains conversation history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "zk6KM4eU2r4b",
        "outputId": "aa6c3a3b-99d5-4e8d-9330-a184d541d52e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--model MODEL] [--api_key API_KEY]\n",
            "                                [--history_length HISTORY_LENGTH]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-4ff23fe0-1956-4622-9454-92b479c134c4.json\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "2",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ],
      "source": [
        "# utils/conversation.py\n",
        "\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "def get_response(prompt, history=None, model_name=\"google/flan-t5-base\", api_key=None, history_length=3):\n",
        "    \"\"\"\n",
        "    Get a response from the model using conversation history\n",
        "\n",
        "    Args:\n",
        "        prompt: The current user prompt\n",
        "        history: List of previous (prompt, response) tuples\n",
        "        model_name: Name of the model to use\n",
        "        api_key: API key for authentication\n",
        "        history_length: Number of previous exchanges to include in context\n",
        "\n",
        "    Returns:\n",
        "        The model's response\n",
        "    \"\"\"\n",
        "    # Initialize history if None\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # Keep only the last `history_length` exchanges\n",
        "    history = history[-history_length:]\n",
        "\n",
        "    # Format the full prompt with history\n",
        "    full_prompt = \"\"\n",
        "    for i, (user_msg, bot_msg) in enumerate(history):\n",
        "        full_prompt += f\"User: {user_msg}\\nBot: {bot_msg}\\n\"\n",
        "    full_prompt += f\"User: {prompt}\\nBot:\"\n",
        "\n",
        "    try:\n",
        "        generator = pipeline(\"text2text-generation\", model=model_name)\n",
        "        response = generator(full_prompt, max_new_tokens=100)[0]['generated_text']\n",
        "        return response.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "    \n",
        "def run_chat():\n",
        "    print(\"Welcome to the Contextual LLM Chat! Type 'exit' to quit.\")\n",
        "    history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = get_response(user_input, history)\n",
        "        history.append((user_input, response))\n",
        "        print(\"Bot:\", response)\n",
        "\n",
        "def main():\n",
        "    run_chat()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxgaIcw2x2e"
      },
      "source": [
        "## 3. Testing and Evaluation\n",
        "\n",
        "Create a script to test your chat implementations with specific healthcare questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "iQ-KKdcY2xlj",
        "outputId": "6167f067-35cf-46e9-c1ef-cd0641fffef7"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'one_off_chat'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1954a59ae830>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Import our chat modules - since we're in the same directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mone_off_chat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_response\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mget_one_off_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Optionally import the conversation module if testing that too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# from conversation import get_response as get_contextual_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'one_off_chat'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# utils/test_chat.py\n",
        "\n",
        "import os\n",
        "import csv\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append('utils')\n",
        "\n",
        "# Import our chat modules - since we're in the same directory\n",
        "from one_off_chat import get_response as get_one_off_response\n",
        "# Optionally import the conversation module if testing that too\n",
        "# from conversation import get_response as get_contextual_response\n",
        "\n",
        "def test_chat(questions, model_name=\"google/flan-t5-base\", api_key=None):\n",
        "    \"\"\"\n",
        "    Test the chat function with a list of questions\n",
        "\n",
        "    Args:\n",
        "        questions: A list of questions to test\n",
        "        model_name: Name of the model to use\n",
        "        api_key: API key for authentication\n",
        "\n",
        "    Returns:\n",
        "        A dictionary mapping questions to responses\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for question in questions:\n",
        "        print(f\"Testing question: {question}\")\n",
        "        # Get response using the one-off chat function\n",
        "        response = get_one_off_response(question, model_name, api_key)\n",
        "        results[question] = response\n",
        "\n",
        "    return results\n",
        "\n",
        "# List of healthcare questions to test\n",
        "test_questions = [\n",
        "    \"What are the symptoms of gout?\",\n",
        "    \"How is gout diagnosed?\",\n",
        "    \"What treatments are available for gout?\",\n",
        "    \"What lifestyle changes can help manage gout?\",\n",
        "    \"What foods should be avoided with gout?\"\n",
        "]\n",
        "\n",
        "def save_results(results, output_file=\"results/part_2/example.txt\"):\n",
        "    \"\"\"\n",
        "    Save the test results to a file\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary mapping questions to responses\n",
        "        output_file: Path to the output file\n",
        "    \"\"\"    \n",
        "    Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(output_file, 'w') as f:\n",
        "        # Write header\n",
        "        f.write(\"# LLM Chat Tool Test Results\\n\\n\")\n",
        "\n",
        "        # Write usage examples\n",
        "        f.write(\"## Usage Examples\\n\\n\")\n",
        "        f.write(\"```bash\\n\")\n",
        "        f.write(\"# Run the one-off chat\\n\")\n",
        "        f.write(\"python utils/one_off_chat.py\\n\\n\")\n",
        "        f.write(\"# Run the contextual chat\\n\")\n",
        "        f.write(\"python utils/conversation.py\\n\")\n",
        "        f.write(\"```\\n\\n\")\n",
        "\n",
        "        # Write test results\n",
        "        f.write(\"## Test Results\\n\\n\")\n",
        "        f.write(\"```csv\\n\")\n",
        "        f.write(\"question,response\\n\")\n",
        "\n",
        "        for question, response in results.items():\n",
        "            # Format the question and response for CSV\n",
        "            q = question.replace(',', '').replace('\\n', ' ')\n",
        "            r = response.replace(',', '').replace('\\n', ' ')\n",
        "            f.write(f\"{q},{r}\\n\")\n",
        "\n",
        "        f.write(\"```\\n\")\n",
        "\n",
        "# Run the test and save results\n",
        "if __name__ == \"__main__\":\n",
        "    results = test_chat(test_questions)\n",
        "    save_results(results)\n",
        "    print(\"Test results saved to results/part_2/example.txt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
