{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b25df5d",
      "metadata": {
        "id": "0b25df5d"
      },
      "source": [
        "# Part 3: Prompt Engineering Basics\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this part, you'll experiment with different prompting techniques to improve the quality of responses from Large Language Models (LLMs). You'll compare zero-shot, one-shot, and few-shot prompting approaches and document which works best for different types of questions.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Understand different prompting techniques\n",
        "- Compare zero-shot, one-shot, and few-shot prompting\n",
        "- Analyze the impact of prompt design on response quality\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1cf754da",
      "metadata": {
        "id": "1cf754da"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab0dd80",
      "metadata": {
        "id": "aab0dd80"
      },
      "source": [
        "## 1. Understanding Prompting Techniques\n",
        "\n",
        "LLMs can be prompted in different ways to get better responses:\n",
        "\n",
        "1. **Zero-shot prompting**: Asking the model a question directly without examples\n",
        "2. **One-shot prompting**: Providing one example before asking your question\n",
        "3. **Few-shot prompting**: Providing multiple examples before asking your question\n",
        "\n",
        "## 2. Creating Prompting Templates\n",
        "\n",
        "Your first task is to create templates for different prompting strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7a06b82d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a06b82d",
        "outputId": "337c55fc-1744-4016-bfdb-69983a60f6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-shot prompt:\n",
            "Question: What foods should be avoided by patients with gout?\n",
            "Answer:\n",
            "\n",
            "One-shot prompt:\n",
            "Question: What are the symptoms of gout?\n",
            "Answer: Gout symptoms include sudden severe pain, swelling, redness, and tenderness in joints, often the big toe.\n",
            "\n",
            "Question: What foods should be avoided by patients with gout?\n",
            "Answer:\n",
            "\n",
            "Few-shot prompt:\n",
            "Question: What are the symptoms of gout?\n",
            "Answer: Gout symptoms include sudden severe pain, swelling, redness, and tenderness in joints, often the big toe.\n",
            "\n",
            "Question: How is gout diagnosed?\n",
            "Answer: Gout is diagnosed through physical examination, medical history, blood tests for uric acid levels, and joint fluid analysis to look for urate crystals.\n",
            "\n",
            "Question: What foods should be avoided by patients with gout?\n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "# Define a question to experiment with\n",
        "question = \"What foods should be avoided by patients with gout?\"\n",
        "\n",
        "# Example for one-shot and few-shot prompting\n",
        "example_q = \"What are the symptoms of gout?\"\n",
        "example_a = \"Gout symptoms include sudden severe pain, swelling, redness, and tenderness in joints, often the big toe.\"\n",
        "\n",
        "# Examples for few-shot prompting\n",
        "examples = [\n",
        "    (\"What are the symptoms of gout?\",\n",
        "     \"Gout symptoms include sudden severe pain, swelling, redness, and tenderness in joints, often the big toe.\"),\n",
        "    (\"How is gout diagnosed?\",\n",
        "     \"Gout is diagnosed through physical examination, medical history, blood tests for uric acid levels, and joint fluid analysis to look for urate crystals.\")\n",
        "]\n",
        "\n",
        "# TODO: Create prompting templates\n",
        "# Zero-shot template (just the question)\n",
        "zero_shot_template = \"Question: {question}\\nAnswer:\"\n",
        "\n",
        "# One-shot template (one example + the question)\n",
        "one_shot_template = \"\"\"Question: {example_q}\n",
        "Answer: {example_a}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "# Few-shot template (multiple examples + the question)\n",
        "few_shot_template = \"\"\"Question: {examples[0][0]}\n",
        "Answer: {examples[0][1]}\n",
        "\n",
        "Question: {examples[1][0]}\n",
        "Answer: {examples[1][1]}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "# TODO: Format the templates with your question and examples\n",
        "zero_shot_prompt = zero_shot_template.format(question=question)\n",
        "one_shot_prompt = one_shot_template.format(example_q=example_q, example_a=example_a, question=question)\n",
        "# For few-shot, you'll need to format it with the examples list\n",
        "few_shot_prompt = few_shot_template.format(examples=examples, question=question)\n",
        "\n",
        "print(\"Zero-shot prompt:\")\n",
        "print(zero_shot_prompt)\n",
        "print(\"\\nOne-shot prompt:\")\n",
        "print(one_shot_prompt)\n",
        "print(\"\\nFew-shot prompt:\")\n",
        "print(few_shot_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d338f577",
      "metadata": {
        "id": "d338f577"
      },
      "source": [
        "## 3. Connecting to the LLM API\n",
        "\n",
        "Next, implement a function to send prompts to an LLM API and get responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c3efb0a8",
      "metadata": {
        "id": "c3efb0a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-06-06 18:48:21.955780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749235702.268325    2476 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749235702.363166    2476 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749235703.055628    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749235703.055675    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749235703.055679    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749235703.055682    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-06 18:48:23.105564: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'zero_shot_prompt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#testing\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mZero-shot:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, get_llm_response(\u001b[43mzero_shot_prompt\u001b[49m))\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOne-shot:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, get_llm_response(one_shot_prompt))\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFew-shot:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, get_llm_response(few_shot_prompt))\n",
            "\u001b[31mNameError\u001b[39m: name 'zero_shot_prompt' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "def get_llm_response(prompt, model_name=\"google/flan-t5-base\", api_key=None):\n",
        "    \"\"\"Get a response from the LLM based on the prompt\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=150)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "#testing\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Zero-shot:\\n\", get_llm_response(zero_shot_prompt))\n",
        "    print(\"\\nOne-shot:\\n\", get_llm_response(one_shot_prompt))\n",
        "    print(\"\\nFew-shot:\\n\", get_llm_response(few_shot_prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "673f6472",
      "metadata": {
        "id": "673f6472"
      },
      "source": [
        "## 4. Comparing Prompting Strategies\n",
        "\n",
        "Now, let's compare the different prompting strategies on a set of healthcare questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b29e9ac8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b29e9ac8",
        "outputId": "cd0a2150-7cf5-4b2c-f1f7-fdc5d84aea36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing question: What foods should be avoided by patients with gout?\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'example_q' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[32m     45\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTesting question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         current_prompts = create_prompts(q, \u001b[43mexample_q\u001b[49m, example_a, examples)\n\u001b[32m     48\u001b[39m         results[q] = {}\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m strategy, prompt \u001b[38;5;129;01min\u001b[39;00m current_prompts.items():\n",
            "\u001b[31mNameError\u001b[39m: name 'example_q' is not defined"
          ]
        }
      ],
      "source": [
        "# List of healthcare questions to test\n",
        "questions = [\n",
        "    \"What foods should be avoided by patients with gout?\",\n",
        "    \"What medications are commonly prescribed for gout?\",\n",
        "    \"How can gout flares be prevented?\",\n",
        "    \"Is gout related to diet?\",\n",
        "    \"Can gout be cured permanently?\"\n",
        "]\n",
        "\n",
        "# Define a function to format prompts for each strategy\n",
        "def create_prompts(question, example_q, example_a, examples):\n",
        "    \"\"\"Creates prompts for zero-shot, one-shot, and few-shot strategies.\"\"\"\n",
        "    zero_shot_template = \"Question: {question}\\nAnswer:\"\n",
        "    one_shot_template = \"\"\"Question: {example_q}\n",
        "Answer: {example_a}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    few_shot_template = \"\"\n",
        "    for ex_q, ex_a in examples:\n",
        "        few_shot_template += f\"Question: {ex_q}\\nAnswer: {ex_a}\\n\\n\"\n",
        "    few_shot_template += \"Question: {question}\\nAnswer:\"\n",
        "\n",
        "\n",
        "    zero_shot_prompt = zero_shot_template.format(question=question)\n",
        "    one_shot_prompt = one_shot_template.format(example_q=example_q, example_a=example_a, question=question)\n",
        "    few_shot_prompt = few_shot_template.format(question=question)\n",
        "\n",
        "    return {\n",
        "        \"zero_shot\": zero_shot_prompt,\n",
        "        \"one_shot\": one_shot_prompt,\n",
        "        \"few_shot\": few_shot_prompt\n",
        "    }\n",
        "\n",
        "# TODO: Compare the different prompting strategies on these questions\n",
        "# For each question:\n",
        "# - Create prompts using each strategy\n",
        "# - Get responses from the LLM\n",
        "# - Store the results\n",
        "\n",
        "results = {}\n",
        "api_key = \"YOUR_HUGGINGFACE_API_KEY\" # Replace with your actual API key\n",
        "for q in questions:\n",
        "        print(f\"\\nTesting question: {q}\")\n",
        "        current_prompts = create_prompts(q, example_q, example_a, examples)\n",
        "\n",
        "        results[q] = {}\n",
        "        for strategy, prompt in current_prompts.items():\n",
        "            print(f\"  Strategy: {strategy}\")\n",
        "            response = get_llm_response(prompt, api_key=api_key)\n",
        "            results[q][strategy] = response\n",
        "            print(f\"    Response: {response[:100]}...\") # Print a snippet of the response\n",
        "\n",
        "# Analyze and present the results\n",
        "print(\"\\n--- Comparison Results ---\")\n",
        "for q, strategy_results in results.items():\n",
        "        print(f\"\\nQuestion: {q}\")\n",
        "        for strategy, response in strategy_results.items():\n",
        "            print(f\"  {strategy.capitalize()}: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5c0525",
      "metadata": {
        "id": "2c5c0525"
      },
      "source": [
        "## 5. Evaluating Responses\n",
        "\n",
        "Create a simple evaluation function to score the responses based on the presence of expected keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e1ad9795",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ad9795",
        "outputId": "28d3caf6-1013-489b-adf4-18ff68d0e183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Scoring Responses ---\n",
            "\n",
            "Question: What foods should be avoided by patients with gout?\n",
            "  Zero_shot Score: 0.00\n",
            "  One_shot Score: 0.00\n",
            "  Few_shot Score: 0.00\n",
            "\n",
            "Question: What medications are commonly prescribed for gout?\n",
            "  Zero_shot Score: 0.00\n",
            "  One_shot Score: 0.00\n",
            "  Few_shot Score: 0.00\n",
            "\n",
            "Question: How can gout flares be prevented?\n",
            "  Zero_shot Score: 0.00\n",
            "  One_shot Score: 0.00\n",
            "  Few_shot Score: 0.00\n",
            "\n",
            "Question: Is gout related to diet?\n",
            "  Zero_shot Score: 0.00\n",
            "  One_shot Score: 0.00\n",
            "  Few_shot Score: 0.00\n",
            "\n",
            "Question: Can gout be cured permanently?\n",
            "  Zero_shot Score: 0.00\n",
            "  One_shot Score: 0.00\n",
            "  Few_shot Score: 0.00\n",
            "\n",
            "--- Average Scores per Strategy ---\n",
            "Zero_shot: 0.00\n",
            "One_shot: 0.00\n",
            "Few_shot: 0.00\n",
            "\n",
            "Best performing strategy overall: Zero_shot\n"
          ]
        }
      ],
      "source": [
        "def score_response(response, keywords):\n",
        "    \"\"\"Score a response based on the presence of expected keywords\"\"\"\n",
        "    response = response.lower()\n",
        "    found_keywords = 0\n",
        "    for keyword in keywords:\n",
        "        if keyword.lower() in response:\n",
        "            found_keywords += 1\n",
        "    return found_keywords / len(keywords) if keywords else 0\n",
        "\n",
        "# Expected keywords for each question\n",
        "expected_keywords = {\n",
        "    \"What foods should be avoided by patients with gout?\":\n",
        "        [\"purine\", \"red meat\", \"seafood\", \"alcohol\", \"beer\", \"organ meats\"],\n",
        "    \"What medications are commonly prescribed for gout?\":\n",
        "        [\"nsaids\", \"colchicine\", \"allopurinol\", \"febuxostat\", \"probenecid\", \"corticosteroids\"],\n",
        "    \"How can gout flares be prevented?\":\n",
        "        [\"medication\", \"diet\", \"weight\", \"alcohol\", \"water\", \"exercise\"],\n",
        "    \"Is gout related to diet?\":\n",
        "        [\"yes\", \"purine\", \"food\", \"alcohol\", \"seafood\", \"meat\"],\n",
        "    \"Can gout be cured permanently?\":\n",
        "        [\"manage\", \"treatment\", \"lifestyle\", \"medication\", \"chronic\"]\n",
        "}\n",
        "\n",
        "# TODO: Score the responses and calculate average scores for each strategy\n",
        "strategy_scores = {\n",
        "    \"zero_shot\": [],\n",
        "    \"one_shot\": [],\n",
        "    \"few_shot\": []\n",
        "}\n",
        "\n",
        "print(\"\\n--- Scoring Responses ---\")\n",
        "for q, strategy_results in results.items():\n",
        "    print(f\"\\nQuestion: {q}\")\n",
        "    keywords = expected_keywords.get(q, [])\n",
        "    if not keywords:\n",
        "        print(f\"  No keywords defined for this question.\")\n",
        "        continue\n",
        "\n",
        "    for strategy, response in strategy_results.items():\n",
        "        score = score_response(response, keywords)\n",
        "        strategy_scores[strategy].append(score)\n",
        "        print(f\"  {strategy.capitalize()} Score: {score:.2f}\")\n",
        "\n",
        "# Calculate and print average scores for each strategy\n",
        "average_scores = {\n",
        "    strategy: sum(scores) / len(scores) if scores else 0\n",
        "    for strategy, scores in strategy_scores.items()\n",
        "}\n",
        "\n",
        "print(\"\\n--- Average Scores per Strategy ---\")\n",
        "for strategy, avg_score in average_scores.items():\n",
        "    print(f\"{strategy.capitalize()}: {avg_score:.2f}\")\n",
        "\n",
        "# Determine which strategy performs best overall\n",
        "best_strategy = max(average_scores, key=average_scores.get)\n",
        "print(f\"\\nBest performing strategy overall: {best_strategy.capitalize()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8c92ea",
      "metadata": {
        "id": "df8c92ea"
      },
      "source": [
        "## 6. Saving Results\n",
        "\n",
        "Save your results in a structured format for auto-grading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c54007fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "c54007fe",
        "outputId": "13b5556c-23a1-4543-8136-9712ffefff10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to results/part_3/prompting_results.txt\n"
          ]
        }
      ],
      "source": [
        "# TODO: Save your results to results/part_3/prompting_results.txt\n",
        "# The file should include:\n",
        "# - Raw responses for each question and strategy\n",
        "# - Scores for each question and strategy\n",
        "# - Average scores for each strategy\n",
        "# - The best performing strategy\n",
        "\n",
        "# Example format:\n",
        "\"\"\"\n",
        "# Prompt Engineering Results\n",
        "\n",
        "## Question: What foods should be avoided by patients with gout?\n",
        "\n",
        "### Zero-shot response:\n",
        "[response text]\n",
        "\n",
        "### One-shot response:\n",
        "[response text]\n",
        "\n",
        "### Few-shot response:\n",
        "[response text]\n",
        "\n",
        "--------------------------------------------------\n",
        "\n",
        "## Scores\n",
        "\n",
        "```\n",
        "question,zero_shot,one_shot,few_shot\n",
        "what_foods_should,0.67,0.83,0.83\n",
        "what_medications_are,0.50,0.67,0.83\n",
        "how_can_gout,0.33,0.50,0.67\n",
        "is_gout_related,0.80,0.80,1.00\n",
        "can_gout_be,0.40,0.60,0.80\n",
        "\n",
        "average,0.54,0.68,0.83\n",
        "best_method,few_shot\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# Initialize output_string\n",
        "output_string = \"\"\n",
        "\n",
        "# Add header and raw responses \n",
        "output_string += \"# Prompt Engineering Results\\n\\n\"\n",
        "\n",
        "for q, strategy_results in results.items():\n",
        "    output_string += f\"## Question: {q}\\n\\n\"\n",
        "    for strategy, response in strategy_results.items():\n",
        "        output_string += f\"### {strategy.capitalize()} response:\\n\"\n",
        "        output_string += f\"{response}\\n\\n\"\n",
        "    output_string += \"--------------------------------------------------\\n\\n\"\n",
        "\n",
        "\n",
        "# Add scores section\n",
        "output_string += \"## Scores\\n\\n\"\n",
        "output_string += \"```\\n\"\n",
        "\n",
        "# Header row\n",
        "output_string += \"question,zero_shot,one_shot,few_shot\\n\"\n",
        "\n",
        "# Data rows for each question\n",
        "for i, q in enumerate(questions):\n",
        "    # Simple slugify the question for the row header\n",
        "    q_slug = q.lower().replace(' ', '_').replace('?','').replace(',','')\n",
        "    output_string += f\"{q_slug},\"\n",
        "    scores_for_q = []\n",
        "    for strategy in [\"zero_shot\", \"one_shot\", \"few_shot\"]:\n",
        "        # Find the score for this specific question and strategy\n",
        "        if i < len(strategy_scores[strategy]):\n",
        "             scores_for_q.append(f\"{strategy_scores[strategy][i]:.2f}\")\n",
        "        else:\n",
        "             scores_for_q.append(\"N/A\") # Handle cases where scoring might not have happened\n",
        "    output_string += \",\".join(scores_for_q) + \"\\n\"\n",
        "\n",
        "# Add average row\n",
        "average_scores_list = [f\"{average_scores['zero_shot']:.2f}\", f\"{average_scores['one_shot']:.2f}\", f\"{average_scores['few_shot']:.2f}\"]\n",
        "output_string += f\"average,{','.join(average_scores_list)}\\n\"\n",
        "\n",
        "# Add best method row\n",
        "best_strategy = max(average_scores, key=average_scores.get)\n",
        "output_string += f\"best_method,{best_strategy}\\n\"\n",
        "\n",
        "output_string += \"```\\n\"\n",
        "\n",
        "# TODO: Save your results to results/part_3/prompting_results.txt\n",
        "# Create the directory if it doesn't exist\n",
        "import os\n",
        "results_dir = \"results/part_3\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Write the output string to the file\n",
        "file_path = os.path.join(results_dir, \"prompting_results.txt\")\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(output_string)\n",
        "\n",
        "print(f\"Results saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4078975",
      "metadata": {
        "id": "a4078975"
      },
      "source": [
        "## Progress Checkpoints\n",
        "\n",
        "1. **Prompting Templates**:\n",
        "   - [ ] Create zero-shot template\n",
        "   - [ ] Create one-shot template\n",
        "   - [ ] Create few-shot template\n",
        "   - [ ] Format templates with questions and examples\n",
        "\n",
        "2. **LLM API Integration**:\n",
        "   - [ ] Connect to the Hugging Face API\n",
        "   - [ ] Test with different prompts\n",
        "   - [ ] Handle API errors\n",
        "\n",
        "3. **Comparison and Evaluation**:\n",
        "   - [ ] Compare strategies on multiple questions\n",
        "   - [ ] Score responses based on keywords\n",
        "   - [ ] Determine the best strategy\n",
        "\n",
        "4. **Results and Documentation**:\n",
        "   - [ ] Save results in the required format\n",
        "   - [ ] Document your findings\n",
        "\n",
        "## What to Submit\n",
        "\n",
        "1. Your implementation in a Python script `utils/prompt_comparison.py` that:\n",
        "   - Defines the prompting templates\n",
        "   - Connects to the Hugging Face API\n",
        "   - Compares different prompting strategies\n",
        "   - Scores and evaluates the responses\n",
        "\n",
        "2. The results of your experiments in `results/part_3/prompting_results.txt` with the format shown above\n",
        "\n",
        "The auto-grader will check:\n",
        "1. That your results file contains the required sections\n",
        "2. That your scoring logic correctly identifies keyword presence\n",
        "3. That you've correctly calculated average scores\n",
        "4. That you've identified the best performing method"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
